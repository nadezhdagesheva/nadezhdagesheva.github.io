<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Deep Learning with h2o</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Nadezhda Gesheva</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Data Science with R</a>
</li>
<li>
  <a href="Project_1.html">CV &amp; LOOCV</a>
</li>
<li>
  <a href="Project_2.html">PCA, Clustering &amp; Regularization</a>
</li>
<li>
  <a href="Project_3.html">Ensemble Models</a>
</li>
<li>
  <a href="Project_4.html">DL and stacking</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Deep Learning with h2o</h1>

</div>


<div id="deep-learning-to-predict-showno-show-medical-appointments" class="section level2">
<h2>Deep Learning to predict show/no show medical appointments</h2>
<p><strong>Task 1:</strong></p>
<p><strong>The data set is Medical Appointments dataset from the Kaggle. The goal is to build deep learning models and to experiment with parameter settings.</strong></p>
<p>Load the medical data set. Data prep &amp; cleanining</p>
<pre class="r"><code>library(data.table)
library(magrittr)
library(GGally)

data &lt;- fread(&quot;data\\no-show-data.csv&quot;)
# some data cleaning
data[, c(&quot;PatientId&quot;, &quot;AppointmentID&quot;, &quot;Neighbourhood&quot;) := NULL]
setnames(data,
         c(&quot;No-show&quot;,
           &quot;Age&quot;,
           &quot;Gender&quot;,
           &quot;ScheduledDay&quot;,
           &quot;AppointmentDay&quot;,
           &quot;Scholarship&quot;,
           &quot;Hipertension&quot;,
           &quot;Diabetes&quot;,
           &quot;Alcoholism&quot;,
           &quot;Handcap&quot;,
           &quot;SMS_received&quot;),
         c(&quot;no_show&quot;,
           &quot;age&quot;,
           &quot;gender&quot;,
           &quot;scheduled_day&quot;,
           &quot;appointment_day&quot;,
           &quot;scholarship&quot;,
           &quot;hypertension&quot;,
           &quot;diabetes&quot;,
           &quot;alcoholism&quot;,
           &quot;handicap&quot;,
           &quot;sms_received&quot;))
# for binary prediction, the target variable must be a factor
data[, no_show := factor(no_show, levels = c(&quot;Yes&quot;, &quot;No&quot;))]
data[, handicap := ifelse(handicap &gt; 0, 1, 0)]

# create new variables
data[, gender := factor(gender)]
data[, scholarship := factor(scholarship)]
data[, hypertension := factor(hypertension)]
data[, alcoholism := factor(alcoholism)]
data[, handicap := factor(handicap)]
data[, scheduled_day := as.Date(scheduled_day)]
data[, appointment_day := as.Date(appointment_day)]
data[, days_since_scheduled := as.integer(appointment_day - scheduled_day)]

# clean up a little bit
data &lt;- data[age %between% c(0, 95)]
data &lt;- data[days_since_scheduled &gt; -1]
data[, c(&quot;scheduled_day&quot;, &quot;appointment_day&quot;, &quot;sms_received&quot;) := NULL]</code></pre>
<div id="initialize-h2o" class="section level3">
<h3>Initialize h2o</h3>
<pre class="r"><code>library(h2o)
h2o.init()</code></pre>
<pre><code>##  Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         3 hours 4 minutes 
##     H2O cluster timezone:       Europe/Helsinki 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.20.0.2 
##     H2O cluster version age:    2 months and 13 days  
##     H2O cluster name:           H2O_started_from_R_Nadya_nma573 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   0.56 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.4.4 (2018-03-15)</code></pre>
<pre class="r"><code># h2o.shutdown() &lt;- in case of failing h2o connection
data &lt;- as.h2o(data)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=================================================================| 100%</code></pre>
<p>Define train, validation &amp; test data sets</p>
<pre class="r"><code>split_data &lt;- h2o.splitFrame(data, 
                             ratios = c(0.05, 0.45),
                             seed = 987)

train_set &lt;- split_data[[1]]
valid_set &lt;- split_data[[2]]
test_set &lt;- split_data[[3]]

y &lt;- &quot;no_show&quot;
X &lt;- setdiff(names(data), y)</code></pre>
</div>
<div id="train-a-benchmark-random-forest-model-on-train-evaluate-on-validation-set." class="section level3">
<h3>Train a benchmark Random Forest model on train &amp; evaluate on validation set.</h3>
<pre class="r"><code>RF_params &lt;- list(ntrees = c(500), mtries = c(3, 5), max_depth = c(2,5))
RF_grid &lt;- h2o.grid(x = X,
                    y = y,
                    training_frame = train_set,
                    algorithm = &#39;randomForest&#39;,
                    seed = 987,
                    hyper_params = RF_params)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |==                                                               |   3%
  |                                                                       
  |====                                                             |   7%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |===========                                                      |  17%
  |                                                                       
  |==================                                               |  27%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |======================                                           |  33%
  |                                                                       
  |=======================                                          |  36%
  |                                                                       
  |================================                                 |  49%
  |                                                                       
  |===================================                              |  53%
  |                                                                       
  |=====================================                            |  56%
  |                                                                       
  |=======================================                          |  59%
  |                                                                       
  |==========================================                       |  65%
  |                                                                       
  |==================================================               |  77%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |======================================================           |  83%
  |                                                                       
  |=======================================================          |  85%
  |                                                                       
  |===============================================================  |  96%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>h2o.getGrid(grid_id = RF_grid@grid_id, sort_by = &quot;AUC&quot;, decreasing = FALSE)</code></pre>
<pre><code>## H2O Grid Details
## ================
## 
## Grid ID: Grid_DRF_RTMP_sid_aea2_11_model_R_1535524973522_6289 
## Used hyper parameters: 
##   -  max_depth 
##   -  mtries 
##   -  ntrees 
## Number of models: 4 
## Number of failed models: 0 
## 
## Hyper-Parameter Search Summary: ordered by increasing AUC
##   max_depth mtries ntrees
## 1         2      3    500
## 2         2      5    500
## 3         5      5    500
## 4         5      3    500
##                                                      model_ids
## 1 Grid_DRF_RTMP_sid_aea2_11_model_R_1535524973522_6289_model_0
## 2 Grid_DRF_RTMP_sid_aea2_11_model_R_1535524973522_6289_model_2
## 3 Grid_DRF_RTMP_sid_aea2_11_model_R_1535524973522_6289_model_3
## 4 Grid_DRF_RTMP_sid_aea2_11_model_R_1535524973522_6289_model_1
##                  auc
## 1 0.7054738653078162
## 2 0.7076334700268355
## 3 0.7137728190291874
## 4 0.7147921425572161</code></pre>
<pre class="r"><code># get the best model with the OOB highest AUC = 0.7147921425572161 - with index 2
RF_model &lt;- h2o.getModel(h2o.getGrid(RF_grid@grid_id)@model_ids[[2]])
RF_model</code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: drf
## Model ID:  Grid_DRF_RTMP_sid_aea2_11_model_R_1535524973522_6289_model_1 
## Model Summary: 
##   number_of_trees number_of_internal_trees model_size_in_bytes min_depth
## 1             500                      500              199068         5
##   max_depth mean_depth min_leaves max_leaves mean_leaves
## 1         5    5.00000         12         32    26.54400
## 
## 
## H2OBinomialMetrics: drf
## ** Reported on training data. **
## ** Metrics reported on Out-Of-Bag training samples **
## 
## MSE:  0.1450657
## RMSE:  0.3808749
## LogLoss:  0.4467068
## Mean Per-Class Error:  0.3275431
## AUC:  0.7147921
## Gini:  0.4295843
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     2191 2213 0.502498  =2213/4404
## Yes     168  933 0.152589   =168/1101
## Totals 2359 3146 0.432516  =2381/5505
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold    value idx
## 1                       max f1  0.209504 0.439369 233
## 2                       max f2  0.141280 0.640286 285
## 3                 max f0point5  0.290586 0.367246 119
## 4                 max accuracy  0.388227 0.800182  15
## 5                max precision  0.388227 0.518519  15
## 6                   max recall  0.037596 1.000000 397
## 7              max specificity  0.522472 0.999773   0
## 8             max absolute_mcc  0.161124 0.292439 278
## 9   max min_per_class_accuracy  0.245832 0.635104 182
## 10 max mean_per_class_accuracy  0.161124 0.674955 278
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre>
<pre class="r"><code>h2o.auc(h2o.performance(RF_model, newdata = valid_set))</code></pre>
<pre><code>## [1] 0.7222011</code></pre>
<p><strong>AUC of benchmark RF model on validation set = 0.7222011.</strong></p>
</div>
</div>
<div id="deep-learning-models" class="section level2">
<h2>Deep Learning models</h2>
<div id="step-1---experiment-with" class="section level3">
<h3>Step 1 - experiment with:</h3>
<ol style="list-style-type: lower-alpha">
<li><p>Models DL_model_1a: shallower layers with more neurons (2 layers with 200 neurons per layer)</p></li>
<li><p>Models DL_model_1b: deeper layer architecture with less neurons per leayer (5 layers with 50 neurons).</p></li>
</ol>
</div>
<div id="dl_model_1a" class="section level3">
<h3>DL_model_1a</h3>
<pre class="r"><code>DL_model_1a &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(200, 200),
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987
  )</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_1a, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.7132144</code></pre>
<p><strong>Validation AUC for DL_model_1a = 0.7132144</strong></p>
</div>
<div id="dl_model_1b" class="section level3">
<h3>DL_model_1b</h3>
<pre class="r"><code>DL_model_1b &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(50, 50, 50, 50, 50),
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987
)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_1b, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.7092839</code></pre>
<p><strong>Validation AUC for DL_model_1b = 0.7092839</strong></p>
<p><em>DL_model_1a(less layers with more nodes) performs better on the validation set. Thus, I will continue further experiments with it.</em></p>
</div>
</div>
<div id="step-2" class="section level2">
<h2>Step 2</h2>
<div id="experiment-with-dropoutboth-hidden-and-input-layers-with-dl_model_1a" class="section level3">
<h3>Experiment with Dropout(both hidden and input layers) with DL_model_1a</h3>
</div>
<div id="dl_model_3a" class="section level3">
<h3>DL_model_3a</h3>
<pre class="r"><code># Lower ratios to both input and hidden layers
DL_model_3a &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  activation = &#39;RectifierWithDropout&#39;,
  hidden = c(200, 200),
  input_dropout_ratio = 0.1,
  hidden_dropout_ratios = c(0.3, 0.3),
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987
)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_3a, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.7111045</code></pre>
<p><strong>AUC = 0.7111045 (still not higher AUC compared to original DL_model_1a)</strong></p>
</div>
<div id="dl_model_3b" class="section level3">
<h3>DL_model_3b</h3>
<pre class="r"><code># Higher ratios to both input and hidden layers
DL_model_3b &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  activation = &#39;RectifierWithDropout&#39;,
  hidden = c(200, 200),
  input_dropout_ratio = 0.2,
  hidden_dropout_ratios = c(0.7, 0.7),
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987
)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_3b, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.6870698</code></pre>
<p><strong>AUC = 0.6870698 (pretty low since we increased the drop-out ratio significantly)</strong></p>
</div>
<div id="step-3" class="section level3">
<h3>Step 3</h3>
</div>
<div id="continue-with-the-original-model-dl_model_1a-and-implement-lassoridge-regularization" class="section level3">
<h3>Continue with the original model DL_model_1a and implement lasso/ridge regularization</h3>
</div>
<div id="dl_model_5a" class="section level3">
<h3>DL_model_5a</h3>
<pre class="r"><code># Lasso
DL_model_5a &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(200, 200),
  l1 = 1e-4,
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987
)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_5a, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.7133694</code></pre>
<p><strong>AUC = 0.7133694 on validation set. This Deep Learning model with lasso regularization outperforms all previous.</strong></p>
</div>
<div id="dl_model_5b" class="section level3">
<h3>DL_model_5b</h3>
<pre class="r"><code># Change l1 value(penalty) and explore the result
DL_model_5b &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(200, 200),
  l1 = 1e-6,
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987
)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_5b, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.713491</code></pre>
<p><strong>AUC = 0.713491 (even better!!!)</strong></p>
</div>
<div id="ridge" class="section level3">
<h3>Ridge</h3>
</div>
<div id="dl_model_5c" class="section level3">
<h3>DL_model_5c</h3>
<pre class="r"><code># Check whether regularization with ridge would bring an improvement
DL_model_5c &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(200, 200),
  l2 = 1e-4,
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987
)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_5c, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.7134781</code></pre>
<p><strong>AUC = 0.7134781 (outperforms lasso with value for l1=1e-04, but not lasso with l1=1e-6)</strong></p>
</div>
<div id="dl_model_5d" class="section level3">
<h3>DL_model_5d</h3>
<pre class="r"><code># Check with l2 = 1e-6
DL_model_5d &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(200, 200),
  l2 = 1e-6,
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>h2o.performance(DL_model_5d, valid_set)@metrics$AUC</code></pre>
<pre><code>## [1] 0.7132411</code></pre>
<p><strong>AUC = 0.7132411 (weaker performance)</strong></p>
<p><em>Currently, DL_model_5b (with lasso l1=1e-6) performs the best on validation set with AUC = 0.713491.</em></p>
</div>
<div id="step-4" class="section level3">
<h3>Step 4</h3>
</div>
<div id="stopping-rounds-tolerance-nb-of-epocs" class="section level3">
<h3>Stopping rounds, tolerance &amp; nb of epocs</h3>
</div>
<div id="dl_model_6b" class="section level3">
<h3>DL_model_6b</h3>
<pre class="r"><code># stopping rounds = 10 (double the default of 5)
DL_model_6b &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(200, 200),
  l1 = 1e-6,
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;, 
  stopping_rounds = 10,
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987
)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_6b, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.713491</code></pre>
<p><strong>AUC = 0.713491 (no change occurs in predictive power when we vary the stopping_rounds).</strong></p>
<p><em>Try combining it with the stopping_tolerance hyperparameter.Experiment with when the moving average of length 2 does not improve by at least 1% for 2 consecutive scoring events.</em></p>
</div>
<div id="dl_model_7a" class="section level3">
<h3>DL_model_7a</h3>
<pre class="r"><code># check with 1% improvement per any 2 consecutive scoring events
DL_model_7a &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(200, 200),
  l1 = 1e-6,
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;, 
  stopping_rounds = 2,
  stopping_tolerance=0.01,
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_7a, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.7123891</code></pre>
<p><strong>AUC = 0.7123891 (lower performance bc we initiated an earlier stop).</strong></p>
</div>
<div id="experiment-with-various-nb-of-epocs" class="section level3">
<h3>Experiment with various nb of epocs</h3>
</div>
<div id="dl_model_8a" class="section level3">
<h3>DL_model_8a</h3>
<pre class="r"><code># First try is with 50(instead of the default which equals 10)
DL_model_8a &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(200, 200),
  l1 = 1e-6,
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  epochs = 50,
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=                                                                |   2%
  |                                                                       
  |===                                                              |   4%
  |                                                                       
  |====                                                             |   6%
  |                                                                       
  |=====                                                            |   8%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |========                                                         |  12%
  |                                                                       
  |=========                                                        |  14%
  |                                                                       
  |==========                                                       |  16%
  |                                                                       
  |============                                                     |  18%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |==============                                                   |  22%
  |                                                                       
  |================                                                 |  24%
  |                                                                       
  |=================                                                |  26%
  |                                                                       
  |==================                                               |  28%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |=====================                                            |  32%
  |                                                                       
  |======================                                           |  34%
  |                                                                       
  |=======================                                          |  36%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_8a, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.7147841</code></pre>
<p><strong>AUC = 0.7147841 (beats previous top performer whose AUC was 0.713491!). Indeed the training epochs matter and are essential deteminant of how the DL model learns.</strong></p>
</div>
<div id="dl_model_8b" class="section level3">
<h3>DL_model_8b</h3>
<pre class="r"><code># Second try is with 100(double the previous iteration)
DL_model_8b &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(200, 200),
  l1 = 1e-6,
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  epochs = 100,
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=                                                                |   1%
  |                                                                       
  |=                                                                |   2%
  |                                                                       
  |==                                                               |   3%
  |                                                                       
  |===                                                              |   4%
  |                                                                       
  |===                                                              |   5%
  |                                                                       
  |====                                                             |   6%
  |                                                                       
  |=====                                                            |   7%
  |                                                                       
  |=====                                                            |   8%
  |                                                                       
  |======                                                           |   9%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=======                                                          |  11%
  |                                                                       
  |========                                                         |  12%
  |                                                                       
  |========                                                         |  13%
  |                                                                       
  |=========                                                        |  14%
  |                                                                       
  |==========                                                       |  15%
  |                                                                       
  |==========                                                       |  16%
  |                                                                       
  |===========                                                      |  17%
  |                                                                       
  |============                                                     |  18%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.performance(DL_model_8b, valid_set)@metrics$AUC)</code></pre>
<pre><code>## [1] 0.7147841</code></pre>
<p><strong>AUC = 0.7147841 (same as previous one). It seems that increasing the training epocs to 100 does not bring additional performance improvement. Hence, I decide to keep DL_model_8a (less complex model with the same performance.)</strong></p>
<p><strong>On the validation dataset:</strong></p>
<p><em>It seems that the benchmark model of RF(RF_model) got AUC of 0.722178 which outperforms any deep learning model that I built including the top performer(DL_model_8a) with AUC = 0.7147627.</em></p>
</div>
<div id="lets-check-how-the-benchmark-rf-and-top-deep-learning-model-perform-on-the-test-data." class="section level3">
<h3>Letâ€™s check how the benchmark RF and top deep learning model perform on the test data.</h3>
<pre class="r"><code>h2o.performance(RF_model, test_set)@metrics$AUC  # AUC = 0.7184559</code></pre>
<pre><code>## [1] 0.7184559</code></pre>
<pre class="r"><code>h2o.performance(DL_model_8a, test_set)@metrics$AUC # AUC = 0.7086608</code></pre>
<pre><code>## [1] 0.7086608</code></pre>
<p><strong>On test set:</strong></p>
<p><strong>Again RF algo outperforms the top deep learning model.</strong></p>
<p><em>Deep learning algorithms necessitate large datasets to work well(where our train set for the medical data consists of only 5505 observations), and there is also the need to train them in reasonable time(low learning rate). They also work best on image classification, NLP and speech recognition. Since our problem asks to predict a binary outcome of show or no-show patients, indeed we might expect that a Random Forest model might perform better(still in terms of AUC both models are pretty close).</em></p>
</div>
</div>
<div id="stacking-with-4-base-learners-to-predict-showno-show-medical-appointments" class="section level2">
<h2>Stacking with 4 base learners to predict show/no show medical appointments</h2>
<p><strong>Task 2:</strong></p>
<p><strong>Employ the same data set and data splits.</strong></p>
<div id="build-models-of-4-families-with-cv-estimate-perf-on-valid-set" class="section level3">
<h3>Build models of 4 families with cv &amp; estimate perf on valid set</h3>
</div>
<div id="model-1---generalized-logistic-model-with-lasso-regularization" class="section level3">
<h3>Model 1 - generalized logistic model with lasso regularization</h3>
<pre class="r"><code>glm_fit &lt;- h2o.glm(X, y, 
                   training_frame = train_set,
                   family = &#39;binomial&#39;,
                   alpha = 1,
                   nfolds = 5, 
                   seed = 987,
                   keep_cross_validation_predictions = TRUE
                   )</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |==                                                               |   2%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.auc(glm_fit, xval = TRUE))</code></pre>
<pre><code>## [1] 0.6366341</code></pre>
<pre class="r"><code># AUC on train set = 0.6366341

print(h2o.auc(h2o.performance(glm_fit, newdata = valid_set, xval = TRUE)))</code></pre>
<pre><code>## [1] 0.6629798</code></pre>
<pre class="r"><code># AUC on valid set = 0.6629798</code></pre>
</div>
<div id="model-2---random-forest" class="section level3">
<h3>Model 2 - Random Forest</h3>
<pre class="r"><code>rf_params &lt;- list(ntrees = c(500), mtries = c(3), max_depth = c(5))
rf_grid &lt;- h2o.grid(x = X,
                    y = y,
                    training_frame = train_set,
                    algorithm = &#39;randomForest&#39;,
                    nfolds = 5,
                    seed = 987,
                    hyper_params = rf_params,
                    keep_cross_validation_predictions = TRUE)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=                                                                |   1%
  |                                                                       
  |=                                                                |   2%
  |                                                                       
  |==                                                               |   3%
  |                                                                       
  |===                                                              |   5%
  |                                                                       
  |=========                                                        |  14%
  |                                                                       
  |===========                                                      |  17%
  |                                                                       
  |============                                                     |  18%
  |                                                                       
  |============                                                     |  19%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |=================                                                |  25%
  |                                                                       
  |======================                                           |  33%
  |                                                                       
  |======================                                           |  34%
  |                                                                       
  |===========================                                      |  42%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=================================                                |  51%
  |                                                                       
  |==================================                               |  52%
  |                                                                       
  |==================================                               |  53%
  |                                                                       
  |===================================                              |  53%
  |                                                                       
  |========================================                         |  62%
  |                                                                       
  |============================================                     |  67%
  |                                                                       
  |============================================                     |  68%
  |                                                                       
  |=============================================                    |  69%
  |                                                                       
  |=============================================                    |  70%
  |                                                                       
  |================================================                 |  74%
  |                                                                       
  |======================================================           |  83%
  |                                                                       
  |=======================================================          |  85%
  |                                                                       
  |========================================================         |  87%
  |                                                                       
  |=========================================================        |  88%
  |                                                                       
  |===========================================================      |  90%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>rf_model &lt;- h2o.getModel(h2o.getGrid(rf_grid@grid_id)@model_ids[[1]])

print(h2o.auc(rf_model, xval = TRUE))</code></pre>
<pre><code>## [1] 0.7127351</code></pre>
<pre class="r"><code># AUC on train = 0.7127351

print(h2o.auc(h2o.performance(rf_model, newdata = valid_set, xval = TRUE)))</code></pre>
<pre><code>## [1] 0.7222011</code></pre>
<pre class="r"><code># AUC on valid set = 0.7222011</code></pre>
</div>
<div id="model-3---gradient-boosting" class="section level3">
<h3>Model 3 - Gradient Boosting</h3>
<pre class="r"><code>gbm_model &lt;- h2o.gbm(
  X, y,
  training_frame = train_set,
  ntrees = 200, 
  max_depth = 10, 
  learn_rate = 0.1, 
  seed = 987,
  nfolds = 5, 
  keep_cross_validation_predictions = TRUE)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |====                                                             |   5%
  |                                                                       
  |=======                                                          |  10%
  |                                                                       
  |==========                                                       |  15%
  |                                                                       
  |===============                                                  |  23%
  |                                                                       
  |=======================                                          |  36%
  |                                                                       
  |==============================================                   |  72%
  |                                                                       
  |======================================================           |  83%
  |                                                                       
  |========================================================         |  87%
  |                                                                       
  |===========================================================      |  91%
  |                                                                       
  |===============================================================  |  96%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.auc(gbm_model, xval = TRUE))</code></pre>
<pre><code>## [1] 0.6832158</code></pre>
<pre class="r"><code># AUC on train = 0.6832158

print(h2o.auc(h2o.performance(gbm_model, newdata = valid_set, xval = TRUE)))</code></pre>
<pre><code>## [1] 0.6885345</code></pre>
<pre class="r"><code># AUC on valid set = 0.6885345</code></pre>
</div>
<div id="model-4---deep-learning-with-cv" class="section level3">
<h3>Model 4 - Deep Learning with CV</h3>
<pre class="r"><code>deeplearning_model &lt;- h2o.deeplearning(
  X, y,
  training_frame = train_set,
  hidden = c(200, 200),
  l1 = 1e-6,
  validation_frame = valid_set,
  stopping_metric = &#39;AUC&#39;,  
  nfolds = 5,
  keep_cross_validation_predictions = TRUE,
  reproducible = TRUE,
  seed = 987)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |===                                                              |   5%
  |                                                                       
  |======                                                           |   9%
  |                                                                       
  |=========                                                        |  13%
  |                                                                       
  |==========                                                       |  16%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |================                                                 |  25%
  |                                                                       
  |===================                                              |  29%
  |                                                                       
  |======================                                           |  33%
  |                                                                       
  |=======================                                          |  36%
  |                                                                       
  |============================                                     |  43%
  |                                                                       
  |===============================                                  |  48%
  |                                                                       
  |===================================                              |  53%
  |                                                                       
  |======================================                           |  59%
  |                                                                       
  |==========================================                       |  64%
  |                                                                       
  |=============================================                    |  69%
  |                                                                       
  |===============================================                  |  72%
  |                                                                       
  |===================================================              |  79%
  |                                                                       
  |=======================================================          |  85%
  |                                                                       
  |==========================================================       |  89%
  |                                                                       
  |===========================================================      |  91%
  |                                                                       
  |=============================================================    |  93%
  |                                                                       
  |==============================================================   |  95%
  |                                                                       
  |===============================================================  |  97%
  |                                                                       
  |================================================================ |  98%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.auc(deeplearning_model, xval = TRUE))</code></pre>
<pre><code>## [1] 0.6492181</code></pre>
<pre class="r"><code># AUC on train = 0.6492181 (a bit better performance than the glm with lasso)

print(h2o.auc(h2o.performance(deeplearning_model, newdata = valid_set, xval = TRUE)))</code></pre>
<pre><code>## [1] 0.712894</code></pre>
<pre class="r"><code># AUC on valid set = 0.712894 (second best after random forest)</code></pre>
<p><strong>Best individual performance with CV is RF: AUC on valid set = 0.7222011.</strong></p>
</div>
<div id="correlations-bw-base-learners-on-validation-set" class="section level3">
<h3>Correlations bw base learners on validation set</h3>
<pre class="r"><code>predictions &lt;- data.table(
  &quot;glm&quot; = as.data.frame(h2o.predict(glm_fit, newdata = valid_set)$Yes)$Yes,
  &quot;rf&quot; = as.data.frame(h2o.predict(rf_model, newdata = valid_set)$Yes)$Yes,
  &quot;gbm&quot; = as.data.frame(h2o.predict(gbm_model, newdata = valid_set)$Yes)$Yes,
  &quot;dl&quot; = as.data.frame(h2o.predict(deeplearning_model, newdata = valid_set)$Yes)$Yes)</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=================================================================| 100%
## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=================================================================| 100%
## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=================================================================| 100%
## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>ggcorr(predictions, label = TRUE, label_round = 2)</code></pre>
<p><img src="Project_4_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p><strong>Highest correlation: dl &amp; rf</strong></p>
<p><strong>Lowest correlation: gbm &amp; glm</strong></p>
</div>
<div id="we-will-create-3-ensemble-models-by-defining-3-meta-learners" class="section level3">
<h3>We will create 3 ensemble models by defining 3 meta learners:</h3>
<ul>
<li><p>Default Random Forest</p></li>
<li><p>Gradient boosting</p></li>
<li><p>Deep Learning</p></li>
</ul>
<p><em>Note: </em></p>
<p><em>I am not sure how to implement seed in the stacked ensemble models. Although the documentation states that there is a seed option, it gives me error message. Oddly enough, the AUC does not change for ensemble model with metalearner â€˜gbmâ€™, but it does for â€˜glmâ€™, â€˜drfâ€™ &amp; â€˜deeplearningâ€™.</em></p>
<p>Default Random Forest as a metalearner</p>
<pre class="r"><code>ensemble_drf &lt;- h2o.stackedEnsemble(
  X, y,
  training_frame = train_set,
  metalearner_algorithm = &quot;drf&quot;,
  base_models = list(glm_fit,
                     rf_model,
                     gbm_model,
                     deeplearning_model))</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.auc(h2o.performance(ensemble_drf, newdata = valid_set)))</code></pre>
<pre><code>## [1] 0.6829177</code></pre>
<p><strong>Poorer performance when compared to individual RF model &amp; deep learning model perf on validation set.</strong></p>
<p>GBM as a metalearner</p>
<pre class="r"><code>ensemble_gbm &lt;- h2o.stackedEnsemble(
  X, y,
  training_frame = train_set,
  metalearner_algorithm = &quot;gbm&quot;,
  base_models = list(glm_fit,
                     rf_model,
                     gbm_model,
                     deeplearning_model))</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.auc(h2o.performance(ensemble_gbm, newdata = valid_set)))</code></pre>
<pre><code>## [1] 0.7027191</code></pre>
<p><strong>Performs poorer than individual rf &amp; deep learning models on validation set.</strong></p>
<p>Deep Learning as a metalearner</p>
<pre class="r"><code>ensemble_dl &lt;- h2o.stackedEnsemble(
  X, y,
  training_frame = train_set,
  metalearner_algorithm = &quot;deeplearning&quot;,
  base_models = list(glm_fit,
                     rf_model,
                     gbm_model,
                     deeplearning_model))</code></pre>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=================================================================| 100%</code></pre>
<pre class="r"><code>print(h2o.auc(h2o.performance(ensemble_dl, newdata = valid_set)))</code></pre>
<pre><code>## [1] 0.7144268</code></pre>
<p><strong>Poorer performance when compared to individual RF model &amp; deep learning model perf on validation set.</strong></p>
<p><strong>The best among ensembled models turns out to be the GBM as a metalearner but still worse than individual perf of RF on valid set.</strong></p>
<p><strong>Why didnâ€™t the ensemble model perform better?</strong></p>
<p><em>Conclusion - we did not achieve an improvement of the base learner RF model. One might explain the poor results of the ensemble models on validation set by assuming that by implementing all 4 base learners we also model noise data. Another possible explanation might be the small size of the train data set.</em></p>
</div>
<div id="evaluate-best-ensemble-model-on-test-set---gbm" class="section level3">
<h3>Evaluate best ensemble model on test set - GBM</h3>
<pre class="r"><code>h2o.auc(h2o.performance(ensemble_gbm, newdata = test_set))</code></pre>
<pre><code>## [1] 0.6979972</code></pre>
<p>** Test set AUC = 0.6979972 (a bit worse than valid set AUC = 0.7027191).**</p>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.4.4 (2018-03-15)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 7 x64 (build 7601) Service Pack 1
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=Bulgarian_Bulgaria.1251  LC_CTYPE=Bulgarian_Bulgaria.1251   
## [3] LC_MONETARY=Bulgarian_Bulgaria.1251 LC_NUMERIC=C                       
## [5] LC_TIME=Bulgarian_Bulgaria.1251    
## 
## attached base packages:
## [1] parallel  splines   stats     graphics  grDevices utils     datasets 
## [8] methods   base     
## 
## other attached packages:
##  [1] h2o_3.20.0.2        magrittr_1.5        bindrcpp_0.2.2     
##  [4] gridExtra_2.3       pROC_1.12.1         ROCR_1.0-7         
##  [7] gplots_3.0.1        skimr_1.0.3         gbm_2.1.3          
## [10] survival_2.41-3     randomForest_4.6-14 xgboost_0.71.2     
## [13] rpart.plot_3.0.4    rpart_4.1-13        NbClust_3.0        
## [16] factoextra_1.0.5    GGally_1.4.0        ISLR_1.2           
## [19] MASS_7.3-50         e1071_1.7-0         titanic_0.1.0      
## [22] caret_6.0-80        ggplot2_2.2.1       lattice_0.20-35    
## [25] data.table_1.11.4  
## 
## loaded via a namespace (and not attached):
##  [1] nlme_3.1-131.1     bitops_1.0-6       lubridate_1.7.4   
##  [4] dimRed_0.1.0       RColorBrewer_1.1-2 rprojroot_1.3-2   
##  [7] tools_3.4.4        backports_1.1.2    R6_2.2.2          
## [10] KernSmooth_2.23-15 lazyeval_0.2.1     colorspace_1.3-2  
## [13] nnet_7.3-12        withr_2.1.2        tidyselect_0.2.4  
## [16] mnormt_1.5-5       compiler_3.4.4     cli_1.0.0         
## [19] glmnet_2.0-16      labeling_0.3       caTools_1.17.1    
## [22] scales_0.5.0       sfsmisc_1.1-2      DEoptimR_1.0-8    
## [25] psych_1.8.4        robustbase_0.93-2  stringr_1.3.1     
## [28] digest_0.6.15      foreign_0.8-69     rmarkdown_1.9     
## [31] pkgconfig_2.0.1    htmltools_0.3.6    rlang_0.2.1       
## [34] ddalpha_1.3.4      bindr_0.1.1        jsonlite_1.5      
## [37] gtools_3.8.1       dplyr_0.7.5        ModelMetrics_1.1.0
## [40] RCurl_1.95-4.11    Matrix_1.2-12      Rcpp_0.12.17      
## [43] munsell_0.4.3      abind_1.4-5        stringi_1.1.7     
## [46] yaml_2.1.19        plyr_1.8.4         recipes_0.1.3     
## [49] grid_3.4.4         gdata_2.18.0       pls_2.6-0         
## [52] ggrepel_0.8.0      crayon_1.3.4       knitr_1.20        
## [55] pillar_1.2.3       ggpubr_0.1.7       reshape2_1.4.3    
## [58] codetools_0.2-15   stats4_3.4.4       CVST_0.2-2        
## [61] magic_1.5-8        glue_1.2.0         evaluate_0.10.1   
## [64] foreach_1.4.4      gtable_0.2.0       purrr_0.2.5       
## [67] tidyr_0.8.1        reshape_0.8.7      kernlab_0.9-26    
## [70] assertthat_0.2.0   DRR_0.0.3          gower_0.1.2       
## [73] prodlim_2018.04.18 broom_0.4.4        class_7.3-14      
## [76] geometry_0.3-6     timeDate_3043.102  RcppRoll_0.3.0    
## [79] tibble_1.4.2       iterators_1.0.10   lava_1.6.2        
## [82] ipred_0.9-6</code></pre>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
